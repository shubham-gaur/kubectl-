<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Source: mspanset.go in package runtime</title>
<link href="../../css/light-v0.3.2.css" rel="stylesheet">
<script src="../../jvs/golds-v0.3.2.js"></script>
<body onload="onPageLoad()"><div>

<pre id="header"><code><span class="title">Source File</span>
	mspanset.go

<span class="title">Belonging Package</span>
	<a href="../../pkg/runtime.html">runtime</a>
</code></pre>

<pre class="line-numbers">
<span class="codeline" id="line-1"><code>// Copyright 2020 The Go Authors. All rights reserved.</code></span>
<span class="codeline" id="line-2"><code>// Use of this source code is governed by a BSD-style</code></span>
<span class="codeline" id="line-3"><code>// license that can be found in the LICENSE file.</code></span>
<span class="codeline" id="line-4"><code></code></span>
<span class="codeline" id="line-5"><code>package runtime</code></span>
<span class="codeline" id="line-6"><code></code></span>
<span class="codeline" id="line-7"><code>import (</code></span>
<span class="codeline" id="line-8"><code>	"internal/cpu"</code></span>
<span class="codeline" id="line-9"><code>	"runtime/internal/atomic"</code></span>
<span class="codeline" id="line-10"><code>	"runtime/internal/sys"</code></span>
<span class="codeline" id="line-11"><code>	"unsafe"</code></span>
<span class="codeline" id="line-12"><code>)</code></span>
<span class="codeline" id="line-13"><code></code></span>
<span class="codeline" id="line-14"><code>// A spanSet is a set of *mspans.</code></span>
<span class="codeline" id="line-15"><code>//</code></span>
<span class="codeline" id="line-16"><code>// spanSet is safe for concurrent push and pop operations.</code></span>
<span class="codeline" id="line-17"><code>type spanSet struct {</code></span>
<span class="codeline" id="line-18"><code>	// A spanSet is a two-level data structure consisting of a</code></span>
<span class="codeline" id="line-19"><code>	// growable spine that points to fixed-sized blocks. The spine</code></span>
<span class="codeline" id="line-20"><code>	// can be accessed without locks, but adding a block or</code></span>
<span class="codeline" id="line-21"><code>	// growing it requires taking the spine lock.</code></span>
<span class="codeline" id="line-22"><code>	//</code></span>
<span class="codeline" id="line-23"><code>	// Because each mspan covers at least 8K of heap and takes at</code></span>
<span class="codeline" id="line-24"><code>	// most 8 bytes in the spanSet, the growth of the spine is</code></span>
<span class="codeline" id="line-25"><code>	// quite limited.</code></span>
<span class="codeline" id="line-26"><code>	//</code></span>
<span class="codeline" id="line-27"><code>	// The spine and all blocks are allocated off-heap, which</code></span>
<span class="codeline" id="line-28"><code>	// allows this to be used in the memory manager and avoids the</code></span>
<span class="codeline" id="line-29"><code>	// need for write barriers on all of these. spanSetBlocks are</code></span>
<span class="codeline" id="line-30"><code>	// managed in a pool, though never freed back to the operating</code></span>
<span class="codeline" id="line-31"><code>	// system. We never release spine memory because there could be</code></span>
<span class="codeline" id="line-32"><code>	// concurrent lock-free access and we're likely to reuse it</code></span>
<span class="codeline" id="line-33"><code>	// anyway. (In principle, we could do this during STW.)</code></span>
<span class="codeline" id="line-34"><code></code></span>
<span class="codeline" id="line-35"><code>	spineLock mutex</code></span>
<span class="codeline" id="line-36"><code>	spine     unsafe.Pointer // *[N]*spanSetBlock, accessed atomically</code></span>
<span class="codeline" id="line-37"><code>	spineLen  uintptr        // Spine array length, accessed atomically</code></span>
<span class="codeline" id="line-38"><code>	spineCap  uintptr        // Spine array cap, accessed under lock</code></span>
<span class="codeline" id="line-39"><code></code></span>
<span class="codeline" id="line-40"><code>	// index is the head and tail of the spanSet in a single field.</code></span>
<span class="codeline" id="line-41"><code>	// The head and the tail both represent an index into the logical</code></span>
<span class="codeline" id="line-42"><code>	// concatenation of all blocks, with the head always behind or</code></span>
<span class="codeline" id="line-43"><code>	// equal to the tail (indicating an empty set). This field is</code></span>
<span class="codeline" id="line-44"><code>	// always accessed atomically.</code></span>
<span class="codeline" id="line-45"><code>	//</code></span>
<span class="codeline" id="line-46"><code>	// The head and the tail are only 32 bits wide, which means we</code></span>
<span class="codeline" id="line-47"><code>	// can only support up to 2^32 pushes before a reset. If every</code></span>
<span class="codeline" id="line-48"><code>	// span in the heap were stored in this set, and each span were</code></span>
<span class="codeline" id="line-49"><code>	// the minimum size (1 runtime page, 8 KiB), then roughly the</code></span>
<span class="codeline" id="line-50"><code>	// smallest heap which would be unrepresentable is 32 TiB in size.</code></span>
<span class="codeline" id="line-51"><code>	index headTailIndex</code></span>
<span class="codeline" id="line-52"><code>}</code></span>
<span class="codeline" id="line-53"><code></code></span>
<span class="codeline" id="line-54"><code>const (</code></span>
<span class="codeline" id="line-55"><code>	spanSetBlockEntries = 512 // 4KB on 64-bit</code></span>
<span class="codeline" id="line-56"><code>	spanSetInitSpineCap = 256 // Enough for 1GB heap on 64-bit</code></span>
<span class="codeline" id="line-57"><code>)</code></span>
<span class="codeline" id="line-58"><code></code></span>
<span class="codeline" id="line-59"><code>type spanSetBlock struct {</code></span>
<span class="codeline" id="line-60"><code>	// Free spanSetBlocks are managed via a lock-free stack.</code></span>
<span class="codeline" id="line-61"><code>	lfnode</code></span>
<span class="codeline" id="line-62"><code></code></span>
<span class="codeline" id="line-63"><code>	// popped is the number of pop operations that have occurred on</code></span>
<span class="codeline" id="line-64"><code>	// this block. This number is used to help determine when a block</code></span>
<span class="codeline" id="line-65"><code>	// may be safely recycled.</code></span>
<span class="codeline" id="line-66"><code>	popped uint32</code></span>
<span class="codeline" id="line-67"><code></code></span>
<span class="codeline" id="line-68"><code>	// spans is the set of spans in this block.</code></span>
<span class="codeline" id="line-69"><code>	spans [spanSetBlockEntries]*mspan</code></span>
<span class="codeline" id="line-70"><code>}</code></span>
<span class="codeline" id="line-71"><code></code></span>
<span class="codeline" id="line-72"><code>// push adds span s to buffer b. push is safe to call concurrently</code></span>
<span class="codeline" id="line-73"><code>// with other push and pop operations.</code></span>
<span class="codeline" id="line-74"><code>func (b *spanSet) push(s *mspan) {</code></span>
<span class="codeline" id="line-75"><code>	// Obtain our slot.</code></span>
<span class="codeline" id="line-76"><code>	cursor := uintptr(b.index.incTail().tail() - 1)</code></span>
<span class="codeline" id="line-77"><code>	top, bottom := cursor/spanSetBlockEntries, cursor%spanSetBlockEntries</code></span>
<span class="codeline" id="line-78"><code></code></span>
<span class="codeline" id="line-79"><code>	// Do we need to add a block?</code></span>
<span class="codeline" id="line-80"><code>	spineLen := atomic.Loaduintptr(&amp;b.spineLen)</code></span>
<span class="codeline" id="line-81"><code>	var block *spanSetBlock</code></span>
<span class="codeline" id="line-82"><code>retry:</code></span>
<span class="codeline" id="line-83"><code>	if top &lt; spineLen {</code></span>
<span class="codeline" id="line-84"><code>		spine := atomic.Loadp(unsafe.Pointer(&amp;b.spine))</code></span>
<span class="codeline" id="line-85"><code>		blockp := add(spine, sys.PtrSize*top)</code></span>
<span class="codeline" id="line-86"><code>		block = (*spanSetBlock)(atomic.Loadp(blockp))</code></span>
<span class="codeline" id="line-87"><code>	} else {</code></span>
<span class="codeline" id="line-88"><code>		// Add a new block to the spine, potentially growing</code></span>
<span class="codeline" id="line-89"><code>		// the spine.</code></span>
<span class="codeline" id="line-90"><code>		lock(&amp;b.spineLock)</code></span>
<span class="codeline" id="line-91"><code>		// spineLen cannot change until we release the lock,</code></span>
<span class="codeline" id="line-92"><code>		// but may have changed while we were waiting.</code></span>
<span class="codeline" id="line-93"><code>		spineLen = atomic.Loaduintptr(&amp;b.spineLen)</code></span>
<span class="codeline" id="line-94"><code>		if top &lt; spineLen {</code></span>
<span class="codeline" id="line-95"><code>			unlock(&amp;b.spineLock)</code></span>
<span class="codeline" id="line-96"><code>			goto retry</code></span>
<span class="codeline" id="line-97"><code>		}</code></span>
<span class="codeline" id="line-98"><code></code></span>
<span class="codeline" id="line-99"><code>		if spineLen == b.spineCap {</code></span>
<span class="codeline" id="line-100"><code>			// Grow the spine.</code></span>
<span class="codeline" id="line-101"><code>			newCap := b.spineCap * 2</code></span>
<span class="codeline" id="line-102"><code>			if newCap == 0 {</code></span>
<span class="codeline" id="line-103"><code>				newCap = spanSetInitSpineCap</code></span>
<span class="codeline" id="line-104"><code>			}</code></span>
<span class="codeline" id="line-105"><code>			newSpine := persistentalloc(newCap*sys.PtrSize, cpu.CacheLineSize, &amp;memstats.gcMiscSys)</code></span>
<span class="codeline" id="line-106"><code>			if b.spineCap != 0 {</code></span>
<span class="codeline" id="line-107"><code>				// Blocks are allocated off-heap, so</code></span>
<span class="codeline" id="line-108"><code>				// no write barriers.</code></span>
<span class="codeline" id="line-109"><code>				memmove(newSpine, b.spine, b.spineCap*sys.PtrSize)</code></span>
<span class="codeline" id="line-110"><code>			}</code></span>
<span class="codeline" id="line-111"><code>			// Spine is allocated off-heap, so no write barrier.</code></span>
<span class="codeline" id="line-112"><code>			atomic.StorepNoWB(unsafe.Pointer(&amp;b.spine), newSpine)</code></span>
<span class="codeline" id="line-113"><code>			b.spineCap = newCap</code></span>
<span class="codeline" id="line-114"><code>			// We can't immediately free the old spine</code></span>
<span class="codeline" id="line-115"><code>			// since a concurrent push with a lower index</code></span>
<span class="codeline" id="line-116"><code>			// could still be reading from it. We let it</code></span>
<span class="codeline" id="line-117"><code>			// leak because even a 1TB heap would waste</code></span>
<span class="codeline" id="line-118"><code>			// less than 2MB of memory on old spines. If</code></span>
<span class="codeline" id="line-119"><code>			// this is a problem, we could free old spines</code></span>
<span class="codeline" id="line-120"><code>			// during STW.</code></span>
<span class="codeline" id="line-121"><code>		}</code></span>
<span class="codeline" id="line-122"><code></code></span>
<span class="codeline" id="line-123"><code>		// Allocate a new block from the pool.</code></span>
<span class="codeline" id="line-124"><code>		block = spanSetBlockPool.alloc()</code></span>
<span class="codeline" id="line-125"><code></code></span>
<span class="codeline" id="line-126"><code>		// Add it to the spine.</code></span>
<span class="codeline" id="line-127"><code>		blockp := add(b.spine, sys.PtrSize*top)</code></span>
<span class="codeline" id="line-128"><code>		// Blocks are allocated off-heap, so no write barrier.</code></span>
<span class="codeline" id="line-129"><code>		atomic.StorepNoWB(blockp, unsafe.Pointer(block))</code></span>
<span class="codeline" id="line-130"><code>		atomic.Storeuintptr(&amp;b.spineLen, spineLen+1)</code></span>
<span class="codeline" id="line-131"><code>		unlock(&amp;b.spineLock)</code></span>
<span class="codeline" id="line-132"><code>	}</code></span>
<span class="codeline" id="line-133"><code></code></span>
<span class="codeline" id="line-134"><code>	// We have a block. Insert the span atomically, since there may be</code></span>
<span class="codeline" id="line-135"><code>	// concurrent readers via the block API.</code></span>
<span class="codeline" id="line-136"><code>	atomic.StorepNoWB(unsafe.Pointer(&amp;block.spans[bottom]), unsafe.Pointer(s))</code></span>
<span class="codeline" id="line-137"><code>}</code></span>
<span class="codeline" id="line-138"><code></code></span>
<span class="codeline" id="line-139"><code>// pop removes and returns a span from buffer b, or nil if b is empty.</code></span>
<span class="codeline" id="line-140"><code>// pop is safe to call concurrently with other pop and push operations.</code></span>
<span class="codeline" id="line-141"><code>func (b *spanSet) pop() *mspan {</code></span>
<span class="codeline" id="line-142"><code>	var head, tail uint32</code></span>
<span class="codeline" id="line-143"><code>claimLoop:</code></span>
<span class="codeline" id="line-144"><code>	for {</code></span>
<span class="codeline" id="line-145"><code>		headtail := b.index.load()</code></span>
<span class="codeline" id="line-146"><code>		head, tail = headtail.split()</code></span>
<span class="codeline" id="line-147"><code>		if head &gt;= tail {</code></span>
<span class="codeline" id="line-148"><code>			// The buf is empty, as far as we can tell.</code></span>
<span class="codeline" id="line-149"><code>			return nil</code></span>
<span class="codeline" id="line-150"><code>		}</code></span>
<span class="codeline" id="line-151"><code>		// Check if the head position we want to claim is actually</code></span>
<span class="codeline" id="line-152"><code>		// backed by a block.</code></span>
<span class="codeline" id="line-153"><code>		spineLen := atomic.Loaduintptr(&amp;b.spineLen)</code></span>
<span class="codeline" id="line-154"><code>		if spineLen &lt;= uintptr(head)/spanSetBlockEntries {</code></span>
<span class="codeline" id="line-155"><code>			// We're racing with a spine growth and the allocation of</code></span>
<span class="codeline" id="line-156"><code>			// a new block (and maybe a new spine!), and trying to grab</code></span>
<span class="codeline" id="line-157"><code>			// the span at the index which is currently being pushed.</code></span>
<span class="codeline" id="line-158"><code>			// Instead of spinning, let's just notify the caller that</code></span>
<span class="codeline" id="line-159"><code>			// there's nothing currently here. Spinning on this is</code></span>
<span class="codeline" id="line-160"><code>			// almost definitely not worth it.</code></span>
<span class="codeline" id="line-161"><code>			return nil</code></span>
<span class="codeline" id="line-162"><code>		}</code></span>
<span class="codeline" id="line-163"><code>		// Try to claim the current head by CASing in an updated head.</code></span>
<span class="codeline" id="line-164"><code>		// This may fail transiently due to a push which modifies the</code></span>
<span class="codeline" id="line-165"><code>		// tail, so keep trying while the head isn't changing.</code></span>
<span class="codeline" id="line-166"><code>		want := head</code></span>
<span class="codeline" id="line-167"><code>		for want == head {</code></span>
<span class="codeline" id="line-168"><code>			if b.index.cas(headtail, makeHeadTailIndex(want+1, tail)) {</code></span>
<span class="codeline" id="line-169"><code>				break claimLoop</code></span>
<span class="codeline" id="line-170"><code>			}</code></span>
<span class="codeline" id="line-171"><code>			headtail = b.index.load()</code></span>
<span class="codeline" id="line-172"><code>			head, tail = headtail.split()</code></span>
<span class="codeline" id="line-173"><code>		}</code></span>
<span class="codeline" id="line-174"><code>		// We failed to claim the spot we were after and the head changed,</code></span>
<span class="codeline" id="line-175"><code>		// meaning a popper got ahead of us. Try again from the top because</code></span>
<span class="codeline" id="line-176"><code>		// the buf may not be empty.</code></span>
<span class="codeline" id="line-177"><code>	}</code></span>
<span class="codeline" id="line-178"><code>	top, bottom := head/spanSetBlockEntries, head%spanSetBlockEntries</code></span>
<span class="codeline" id="line-179"><code></code></span>
<span class="codeline" id="line-180"><code>	// We may be reading a stale spine pointer, but because the length</code></span>
<span class="codeline" id="line-181"><code>	// grows monotonically and we've already verified it, we'll definitely</code></span>
<span class="codeline" id="line-182"><code>	// be reading from a valid block.</code></span>
<span class="codeline" id="line-183"><code>	spine := atomic.Loadp(unsafe.Pointer(&amp;b.spine))</code></span>
<span class="codeline" id="line-184"><code>	blockp := add(spine, sys.PtrSize*uintptr(top))</code></span>
<span class="codeline" id="line-185"><code></code></span>
<span class="codeline" id="line-186"><code>	// Given that the spine length is correct, we know we will never</code></span>
<span class="codeline" id="line-187"><code>	// see a nil block here, since the length is always updated after</code></span>
<span class="codeline" id="line-188"><code>	// the block is set.</code></span>
<span class="codeline" id="line-189"><code>	block := (*spanSetBlock)(atomic.Loadp(blockp))</code></span>
<span class="codeline" id="line-190"><code>	s := (*mspan)(atomic.Loadp(unsafe.Pointer(&amp;block.spans[bottom])))</code></span>
<span class="codeline" id="line-191"><code>	for s == nil {</code></span>
<span class="codeline" id="line-192"><code>		// We raced with the span actually being set, but given that we</code></span>
<span class="codeline" id="line-193"><code>		// know a block for this span exists, the race window here is</code></span>
<span class="codeline" id="line-194"><code>		// extremely small. Try again.</code></span>
<span class="codeline" id="line-195"><code>		s = (*mspan)(atomic.Loadp(unsafe.Pointer(&amp;block.spans[bottom])))</code></span>
<span class="codeline" id="line-196"><code>	}</code></span>
<span class="codeline" id="line-197"><code>	// Clear the pointer. This isn't strictly necessary, but defensively</code></span>
<span class="codeline" id="line-198"><code>	// avoids accidentally re-using blocks which could lead to memory</code></span>
<span class="codeline" id="line-199"><code>	// corruption. This way, we'll get a nil pointer access instead.</code></span>
<span class="codeline" id="line-200"><code>	atomic.StorepNoWB(unsafe.Pointer(&amp;block.spans[bottom]), nil)</code></span>
<span class="codeline" id="line-201"><code></code></span>
<span class="codeline" id="line-202"><code>	// Increase the popped count. If we are the last possible popper</code></span>
<span class="codeline" id="line-203"><code>	// in the block (note that bottom need not equal spanSetBlockEntries-1</code></span>
<span class="codeline" id="line-204"><code>	// due to races) then it's our resposibility to free the block.</code></span>
<span class="codeline" id="line-205"><code>	//</code></span>
<span class="codeline" id="line-206"><code>	// If we increment popped to spanSetBlockEntries, we can be sure that</code></span>
<span class="codeline" id="line-207"><code>	// we're the last popper for this block, and it's thus safe to free it.</code></span>
<span class="codeline" id="line-208"><code>	// Every other popper must have crossed this barrier (and thus finished</code></span>
<span class="codeline" id="line-209"><code>	// popping its corresponding mspan) by the time we get here. Because</code></span>
<span class="codeline" id="line-210"><code>	// we're the last popper, we also don't have to worry about concurrent</code></span>
<span class="codeline" id="line-211"><code>	// pushers (there can't be any). Note that we may not be the popper</code></span>
<span class="codeline" id="line-212"><code>	// which claimed the last slot in the block, we're just the last one</code></span>
<span class="codeline" id="line-213"><code>	// to finish popping.</code></span>
<span class="codeline" id="line-214"><code>	if atomic.Xadd(&amp;block.popped, 1) == spanSetBlockEntries {</code></span>
<span class="codeline" id="line-215"><code>		// Clear the block's pointer.</code></span>
<span class="codeline" id="line-216"><code>		atomic.StorepNoWB(blockp, nil)</code></span>
<span class="codeline" id="line-217"><code></code></span>
<span class="codeline" id="line-218"><code>		// Return the block to the block pool.</code></span>
<span class="codeline" id="line-219"><code>		spanSetBlockPool.free(block)</code></span>
<span class="codeline" id="line-220"><code>	}</code></span>
<span class="codeline" id="line-221"><code>	return s</code></span>
<span class="codeline" id="line-222"><code>}</code></span>
<span class="codeline" id="line-223"><code></code></span>
<span class="codeline" id="line-224"><code>// reset resets a spanSet which is empty. It will also clean up</code></span>
<span class="codeline" id="line-225"><code>// any left over blocks.</code></span>
<span class="codeline" id="line-226"><code>//</code></span>
<span class="codeline" id="line-227"><code>// Throws if the buf is not empty.</code></span>
<span class="codeline" id="line-228"><code>//</code></span>
<span class="codeline" id="line-229"><code>// reset may not be called concurrently with any other operations</code></span>
<span class="codeline" id="line-230"><code>// on the span set.</code></span>
<span class="codeline" id="line-231"><code>func (b *spanSet) reset() {</code></span>
<span class="codeline" id="line-232"><code>	head, tail := b.index.load().split()</code></span>
<span class="codeline" id="line-233"><code>	if head &lt; tail {</code></span>
<span class="codeline" id="line-234"><code>		print("head = ", head, ", tail = ", tail, "\n")</code></span>
<span class="codeline" id="line-235"><code>		throw("attempt to clear non-empty span set")</code></span>
<span class="codeline" id="line-236"><code>	}</code></span>
<span class="codeline" id="line-237"><code>	top := head / spanSetBlockEntries</code></span>
<span class="codeline" id="line-238"><code>	if uintptr(top) &lt; b.spineLen {</code></span>
<span class="codeline" id="line-239"><code>		// If the head catches up to the tail and the set is empty,</code></span>
<span class="codeline" id="line-240"><code>		// we may not clean up the block containing the head and tail</code></span>
<span class="codeline" id="line-241"><code>		// since it may be pushed into again. In order to avoid leaking</code></span>
<span class="codeline" id="line-242"><code>		// memory since we're going to reset the head and tail, clean</code></span>
<span class="codeline" id="line-243"><code>		// up such a block now, if it exists.</code></span>
<span class="codeline" id="line-244"><code>		blockp := (**spanSetBlock)(add(b.spine, sys.PtrSize*uintptr(top)))</code></span>
<span class="codeline" id="line-245"><code>		block := *blockp</code></span>
<span class="codeline" id="line-246"><code>		if block != nil {</code></span>
<span class="codeline" id="line-247"><code>			// Sanity check the popped value.</code></span>
<span class="codeline" id="line-248"><code>			if block.popped == 0 {</code></span>
<span class="codeline" id="line-249"><code>				// popped should never be zero because that means we have</code></span>
<span class="codeline" id="line-250"><code>				// pushed at least one value but not yet popped if this</code></span>
<span class="codeline" id="line-251"><code>				// block pointer is not nil.</code></span>
<span class="codeline" id="line-252"><code>				throw("span set block with unpopped elements found in reset")</code></span>
<span class="codeline" id="line-253"><code>			}</code></span>
<span class="codeline" id="line-254"><code>			if block.popped == spanSetBlockEntries {</code></span>
<span class="codeline" id="line-255"><code>				// popped should also never be equal to spanSetBlockEntries</code></span>
<span class="codeline" id="line-256"><code>				// because the last popper should have made the block pointer</code></span>
<span class="codeline" id="line-257"><code>				// in this slot nil.</code></span>
<span class="codeline" id="line-258"><code>				throw("fully empty unfreed span set block found in reset")</code></span>
<span class="codeline" id="line-259"><code>			}</code></span>
<span class="codeline" id="line-260"><code></code></span>
<span class="codeline" id="line-261"><code>			// Clear the pointer to the block.</code></span>
<span class="codeline" id="line-262"><code>			atomic.StorepNoWB(unsafe.Pointer(blockp), nil)</code></span>
<span class="codeline" id="line-263"><code></code></span>
<span class="codeline" id="line-264"><code>			// Return the block to the block pool.</code></span>
<span class="codeline" id="line-265"><code>			spanSetBlockPool.free(block)</code></span>
<span class="codeline" id="line-266"><code>		}</code></span>
<span class="codeline" id="line-267"><code>	}</code></span>
<span class="codeline" id="line-268"><code>	b.index.reset()</code></span>
<span class="codeline" id="line-269"><code>	atomic.Storeuintptr(&amp;b.spineLen, 0)</code></span>
<span class="codeline" id="line-270"><code>}</code></span>
<span class="codeline" id="line-271"><code></code></span>
<span class="codeline" id="line-272"><code>// spanSetBlockPool is a global pool of spanSetBlocks.</code></span>
<span class="codeline" id="line-273"><code>var spanSetBlockPool spanSetBlockAlloc</code></span>
<span class="codeline" id="line-274"><code></code></span>
<span class="codeline" id="line-275"><code>// spanSetBlockAlloc represents a concurrent pool of spanSetBlocks.</code></span>
<span class="codeline" id="line-276"><code>type spanSetBlockAlloc struct {</code></span>
<span class="codeline" id="line-277"><code>	stack lfstack</code></span>
<span class="codeline" id="line-278"><code>}</code></span>
<span class="codeline" id="line-279"><code></code></span>
<span class="codeline" id="line-280"><code>// alloc tries to grab a spanSetBlock out of the pool, and if it fails</code></span>
<span class="codeline" id="line-281"><code>// persistentallocs a new one and returns it.</code></span>
<span class="codeline" id="line-282"><code>func (p *spanSetBlockAlloc) alloc() *spanSetBlock {</code></span>
<span class="codeline" id="line-283"><code>	if s := (*spanSetBlock)(p.stack.pop()); s != nil {</code></span>
<span class="codeline" id="line-284"><code>		return s</code></span>
<span class="codeline" id="line-285"><code>	}</code></span>
<span class="codeline" id="line-286"><code>	return (*spanSetBlock)(persistentalloc(unsafe.Sizeof(spanSetBlock{}), cpu.CacheLineSize, &amp;memstats.gcMiscSys))</code></span>
<span class="codeline" id="line-287"><code>}</code></span>
<span class="codeline" id="line-288"><code></code></span>
<span class="codeline" id="line-289"><code>// free returns a spanSetBlock back to the pool.</code></span>
<span class="codeline" id="line-290"><code>func (p *spanSetBlockAlloc) free(block *spanSetBlock) {</code></span>
<span class="codeline" id="line-291"><code>	atomic.Store(&amp;block.popped, 0)</code></span>
<span class="codeline" id="line-292"><code>	p.stack.push(&amp;block.lfnode)</code></span>
<span class="codeline" id="line-293"><code>}</code></span>
<span class="codeline" id="line-294"><code></code></span>
<span class="codeline" id="line-295"><code>// haidTailIndex represents a combined 32-bit head and 32-bit tail</code></span>
<span class="codeline" id="line-296"><code>// of a queue into a single 64-bit value.</code></span>
<span class="codeline" id="line-297"><code>type headTailIndex uint64</code></span>
<span class="codeline" id="line-298"><code></code></span>
<span class="codeline" id="line-299"><code>// makeHeadTailIndex creates a headTailIndex value from a separate</code></span>
<span class="codeline" id="line-300"><code>// head and tail.</code></span>
<span class="codeline" id="line-301"><code>func makeHeadTailIndex(head, tail uint32) headTailIndex {</code></span>
<span class="codeline" id="line-302"><code>	return headTailIndex(uint64(head)&lt;&lt;32 | uint64(tail))</code></span>
<span class="codeline" id="line-303"><code>}</code></span>
<span class="codeline" id="line-304"><code></code></span>
<span class="codeline" id="line-305"><code>// head returns the head of a headTailIndex value.</code></span>
<span class="codeline" id="line-306"><code>func (h headTailIndex) head() uint32 {</code></span>
<span class="codeline" id="line-307"><code>	return uint32(h &gt;&gt; 32)</code></span>
<span class="codeline" id="line-308"><code>}</code></span>
<span class="codeline" id="line-309"><code></code></span>
<span class="codeline" id="line-310"><code>// tail returns the tail of a headTailIndex value.</code></span>
<span class="codeline" id="line-311"><code>func (h headTailIndex) tail() uint32 {</code></span>
<span class="codeline" id="line-312"><code>	return uint32(h)</code></span>
<span class="codeline" id="line-313"><code>}</code></span>
<span class="codeline" id="line-314"><code></code></span>
<span class="codeline" id="line-315"><code>// split splits the headTailIndex value into its parts.</code></span>
<span class="codeline" id="line-316"><code>func (h headTailIndex) split() (head uint32, tail uint32) {</code></span>
<span class="codeline" id="line-317"><code>	return h.head(), h.tail()</code></span>
<span class="codeline" id="line-318"><code>}</code></span>
<span class="codeline" id="line-319"><code></code></span>
<span class="codeline" id="line-320"><code>// load atomically reads a headTailIndex value.</code></span>
<span class="codeline" id="line-321"><code>func (h *headTailIndex) load() headTailIndex {</code></span>
<span class="codeline" id="line-322"><code>	return headTailIndex(atomic.Load64((*uint64)(h)))</code></span>
<span class="codeline" id="line-323"><code>}</code></span>
<span class="codeline" id="line-324"><code></code></span>
<span class="codeline" id="line-325"><code>// cas atomically compares-and-swaps a headTailIndex value.</code></span>
<span class="codeline" id="line-326"><code>func (h *headTailIndex) cas(old, new headTailIndex) bool {</code></span>
<span class="codeline" id="line-327"><code>	return atomic.Cas64((*uint64)(h), uint64(old), uint64(new))</code></span>
<span class="codeline" id="line-328"><code>}</code></span>
<span class="codeline" id="line-329"><code></code></span>
<span class="codeline" id="line-330"><code>// incHead atomically increments the head of a headTailIndex.</code></span>
<span class="codeline" id="line-331"><code>func (h *headTailIndex) incHead() headTailIndex {</code></span>
<span class="codeline" id="line-332"><code>	return headTailIndex(atomic.Xadd64((*uint64)(h), (1 &lt;&lt; 32)))</code></span>
<span class="codeline" id="line-333"><code>}</code></span>
<span class="codeline" id="line-334"><code></code></span>
<span class="codeline" id="line-335"><code>// decHead atomically decrements the head of a headTailIndex.</code></span>
<span class="codeline" id="line-336"><code>func (h *headTailIndex) decHead() headTailIndex {</code></span>
<span class="codeline" id="line-337"><code>	return headTailIndex(atomic.Xadd64((*uint64)(h), -(1 &lt;&lt; 32)))</code></span>
<span class="codeline" id="line-338"><code>}</code></span>
<span class="codeline" id="line-339"><code></code></span>
<span class="codeline" id="line-340"><code>// incTail atomically increments the tail of a headTailIndex.</code></span>
<span class="codeline" id="line-341"><code>func (h *headTailIndex) incTail() headTailIndex {</code></span>
<span class="codeline" id="line-342"><code>	ht := headTailIndex(atomic.Xadd64((*uint64)(h), +1))</code></span>
<span class="codeline" id="line-343"><code>	// Check for overflow.</code></span>
<span class="codeline" id="line-344"><code>	if ht.tail() == 0 {</code></span>
<span class="codeline" id="line-345"><code>		print("runtime: head = ", ht.head(), ", tail = ", ht.tail(), "\n")</code></span>
<span class="codeline" id="line-346"><code>		throw("headTailIndex overflow")</code></span>
<span class="codeline" id="line-347"><code>	}</code></span>
<span class="codeline" id="line-348"><code>	return ht</code></span>
<span class="codeline" id="line-349"><code>}</code></span>
<span class="codeline" id="line-350"><code></code></span>
<span class="codeline" id="line-351"><code>// reset clears the headTailIndex to (0, 0).</code></span>
<span class="codeline" id="line-352"><code>func (h *headTailIndex) reset() {</code></span>
<span class="codeline" id="line-353"><code>	atomic.Store64((*uint64)(h), 0)</code></span>
<span class="codeline" id="line-354"><code>}</code></span>
</pre><pre id="footer">
<table><tr><td><img src="../../png/go101-twitter.png"></td>
<td>The pages are generated with <a href="https://go101.org/article/tool-golds.html"><b>Golds</b></a> <i>v0.3.2</i>. (GOOS=linux GOARCH=amd64)
<b>Golds</b> is a <a href="https://go101.org">Go 101</a> project developed by <a href="https://tapirgames.com">Tapir Liu</a>.
PR and bug reports are welcome and can be submitted to <a href="https://github.com/go101/golds">the issue list</a>.
Please follow <a href="https://twitter.com/go100and1">@Go100and1</a> (reachable from the left QR code) to get the latest news of <b>Golds</b>.</td></tr></table></pre>